{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To mount your Google Drive in Colab, you can use the following code snippet:\n",
        "\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "```\n",
        "\n",
        "This will prompt you to authorize Colab to access your Google Drive. Once you complete the authorization process, your Drive will be mounted at the specified path ('/content/drive' in this case). You can then access your Drive files using this path."
      ],
      "metadata": {
        "id": "j_AM7Ag7vQae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9YLfbhhvQoF",
        "outputId": "96a812b0-bdf1-4ed0-bf28-6d240f79354a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the EfficientNetV2 model\n",
        "# model = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n",
        "#     include_top=True,\n",
        "#     weights='imagenet',\n",
        "#     input_tensor=None,\n",
        "#     input_shape=None,\n",
        "#     pooling=None,\n",
        "#     classifier_activation='softmax',\n",
        "#     include_preprocessing=True\n",
        "# )\n",
        "\n",
        "# Add a new global average pooling layer followed by a dense layer with sigmoid activation\n",
        "# x = keras.layers.GlobalAveragePooling2D()(model.output)\n",
        "# x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Build the new model\n",
        "# model = keras.models.Model(inputs=model.inputs, outputs=x)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Set the data directory path\n",
        "data_dir = '/content/drive/My Drive/Side_Projects/Image_Classification/dataset/'\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rescale=1./255, # Rescale pixel values between 0 and 1\n",
        "    rotation_range=20, # Rotate images randomly within 20 degrees\n",
        "    width_shift_range=0.2, # Randomly shift images horizontally within 20% of the image width\n",
        "    height_shift_range=0.2, # Randomly shift images vertically within 20% of the image height\n",
        "    shear_range=0.2, # Randomly apply shearing transformations within 20 degrees\n",
        "    zoom_range=0.2, # Randomly zoom in on images within 20% of the original size\n",
        "    horizontal_flip=True, # Flip images horizontally\n",
        "    fill_mode='nearest', # Fill missing pixels with nearest pixel values\n",
        "    validation_split=0.2 # Split 20% of data as validation set\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "# Use flow_from_directory function to create training and testing datasets\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='training' # Specify as training set\n",
        ")S\n",
        "\n",
        "val_dataset = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation' # Specify as validation set\n",
        ")\n",
        "\n",
        "test_dataset = test_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False # Do not shuffle, for evaluation purpose\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/My Drive/Side_Projects/Image_Classification/efficientnetv2.h5')\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "9WTzATfxvkmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Load the saved model for prediction\n",
        "loaded_model = keras.models.load_model('/content/drive/My Drive/Side_Projects/Image_Classification/efficientnetv2.h5')\n",
        "\n",
        "# Predict an image using the loaded model\n",
        "img_path = '/content/drive/My Drive/Side_Projects/Image_Classification/dataset/rain/35.jpg'\n",
        "img = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "prediction = loaded_model.predict(img_array)\n",
        "predicted_class = keras.applications.imagenet_utils.decode_predictions(prediction, top=1)[0][0][1]\n",
        "print('Predicted class:', predicted_class)"
      ],
      "metadata": {
        "id": "m1BtaLjtv023"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}